{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57b6245-a6ed-4d62-8e07-67be85a3a2e1",
   "metadata": {},
   "source": [
    "# Model order reduction with artificial neural networks in pyMOR\n",
    "\n",
    "## Overview\n",
    "- Application: Parametrized PDEs (stationary and instationary)\n",
    "- Theory: Reduced Basis Methods, Proper Orthogonal Decomposition, Artifical Neural Networks\n",
    "- Practice: Implementation in pyMOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af415305-630a-42f9-b687-123f212d187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'pyodide' in sys.modules:\n",
    "    import piplite\n",
    "    await piplite.install(['pymor', 'matplotlib', 'ipython'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e136169-4503-4573-b83a-c5803dab356b",
   "metadata": {},
   "source": [
    "## A non-intrusive reduced order method using artificial neural networks\n",
    "\n",
    "### Two scenarios:\n",
    "\n",
    "- Given a full-order model $\\mu\\mapsto u(\\mu)$, but e.g. no affine decomposition of operators\n",
    "- Given only a set $\\{(\\mu_i,u(\\mu_i))\\}_{i=1}^n$ of parameter values with corresponding snapshots\n",
    "\n",
    "### The approach:\n",
    "\n",
    "- Compute a reduced space $V_N$ with (orthonormal) basis $\\Psi_N$ using only snapshot data (via proper orthogonal decomposition)\n",
    "- Project full-order solution $u(\\mu)$ onto $V_N$ (orthogonal projection!):\n",
    "\\begin{align}\n",
    "    \\pi_N\\colon\\mathcal{P}\\to\\mathbb{R}^N,\\qquad\\pi_N(\\mu)=\\Psi_N^\\top u(\\mu)\n",
    "\\end{align}\n",
    "- Function $\\pi_N$ returns for a parameter $\\mu\\in\\mathcal{P}$ the coefficients of the projection $u_N(\\mu)$ of $u(\\mu)$ onto $V_N$ w.r.t. the basis $\\Psi_N$\n",
    "- Approximate the map $\\pi_N$ by a neural network $\\Phi_N$\n",
    "\n",
    "### Error estimate:\n",
    "\n",
    "\\begin{align}\n",
    "    \\lVert u(\\mu)-\\Psi_N\\Phi_N(\\mu)\\rVert\\leq\\underbrace{\\lVert u(\\mu)-u_N(\\mu)\\rVert}_{\\text{best-approximation error in }V_N} + \\underbrace{\\lVert\\pi_N(\\mu)-\\Phi_N(\\mu)\\rVert}_{\\text{approximation error of the neural network}}\n",
    "\\end{align}\n",
    "\n",
    "### Available variants in pyMOR:\n",
    "\n",
    "| Setting | Inputs | Outputs | Visualization |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| Stationary, State | $\\mu$ | $\\pi_N(\\mu)$ | <img src=\"files/mu_to_coeffs.svg\" alt=\"Feedforward neural network for model order reduction\" width=\"100%\" /> |\n",
    "| Instationary, State | $(\\mu,t)$ | $\\pi_N$$(\\mu,t)$ | <img src=\"files/mu_and_time_to_coeffs.svg\" alt=\"Feedforward neural network for model order reduction\" width=\"100%\" /> |\n",
    "| Stationary, Output | $\\mu$ | $\\mathcal{J}(\\mu)$ | <img src=\"files/mu_to_output.svg\" alt=\"Feedforward neural network for model order reduction\" width=\"100%\" /> |\n",
    "| Instationary, Output | $(\\mu,t)$ | $\\mathcal{J}(\\mu,t)$ | <img src=\"files/mu_and_time_to_output.svg\" alt=\"Feedforward neural network for model order reduction\" width=\"100%\" /> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562dcbf5-8270-4e7c-bf33-c68057aeba7a",
   "metadata": {},
   "source": [
    "## A stationary example in pyMOR\n",
    "\n",
    "### Setting up the problem:\n",
    "\n",
    "Example problem:\n",
    "\\begin{align}\n",
    "    -\\nabla \\cdot \\big(\\sigma(x, \\mu) \\nabla u(x, \\mu) \\big) = f(x, \\mu),\\quad x\\in \\Omega=(0,1)^2,\n",
    "\\end{align}\n",
    "with data functions \n",
    "\\begin{align}\n",
    "    f((x_1, x_2), \\mu) &= 10 \\cdot \\mu + 0.1,\\\\\n",
    "    \\sigma((x_1, x_2), \\mu) &= (1 - x_1) \\cdot \\mu + x_1,\n",
    "\\end{align}\n",
    "where $\\mu \\in (0.1, 1)$ denotes the parameter. Further, we apply the Dirichlet boundary conditions\n",
    "\n",
    "\\begin{align}\n",
    "    u((x_1, x_2), \\mu) = 2x_1\\mu + 0.5,\\quad x=(x_1, x_2) \\in \\partial\\Omega.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604d1328-cf8f-459a-8183-0d92237d1dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pymor.core.logger import set_log_levels\n",
    "set_log_levels({'pymor.discretizers.builtin.cg.DiffusionOperatorP1': 'ERROR', 'pymor.discretizers.builtin.cg.L2ProductP1': 'ERROR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff984d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pymor.basic import *\n",
    "\n",
    "problem = StationaryProblem(\n",
    "      domain=RectDomain(),\n",
    "\n",
    "      rhs=LincombFunction(\n",
    "          [ExpressionFunction('10', 2), ConstantFunction(1., 2)],\n",
    "          [ProjectionParameterFunctional('mu'), 0.1]),\n",
    "\n",
    "      diffusion=LincombFunction(\n",
    "          [ExpressionFunction('1 - x[0]', 2), ExpressionFunction('x[0]', 2)],\n",
    "          [ProjectionParameterFunctional('mu'), 1]),\n",
    "\n",
    "      dirichlet_data=LincombFunction(\n",
    "          [ExpressionFunction('2 * x[0]', 2), ConstantFunction(1., 2)],\n",
    "          [ProjectionParameterFunctional('mu'), 0.5]),\n",
    "\n",
    "      name='2DProblem'\n",
    "  )\n",
    "\n",
    "fom, _ = discretize_stationary_cg(problem, diameter=1/50)\n",
    "\n",
    "parameter_space = fom.parameters.space((0.1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1749f5b-f810-443a-9a10-ea9b6720db2a",
   "metadata": {},
   "source": [
    "### Setting up the neural network reductor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e193f867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set = parameter_space.sample_uniformly(100)\n",
    "validation_set = parameter_space.sample_randomly(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce02ac5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pymor.reductors.neural_network import NeuralNetworkReductor\n",
    "\n",
    "nn_reductor = NeuralNetworkReductor(fom,\n",
    "                                    training_set,\n",
    "                                    validation_set,\n",
    "                                    l2_err=1e-5,  # POD error\n",
    "                                    ann_mse=1e-5)  # Neural network training error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae780783-eab6-42b2-8bfa-8fd36d701741",
   "metadata": {},
   "source": [
    "*Alternative, purely data-driven usage:* Pass pairs of parameters and solutions as training/validation set to the reductor and set `fom=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f33c190-9bef-4911-924c-78306360e4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce by training artificial neural networks.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        hidden_layers\n",
      "            Number of neurons in the hidden layers. Can either be fixed or\n",
      "            a Python expression string depending on the reduced basis size\n",
      "            respectively output dimension `N` and the total dimension of\n",
      "            the |Parameters| `P`.\n",
      "        activation_function\n",
      "            Activation function to use between the hidden layers.\n",
      "        optimizer\n",
      "            Algorithm to use as optimizer during training.\n",
      "        epochs\n",
      "            Maximum number of epochs for training.\n",
      "        batch_size\n",
      "            Batch size to use if optimizer allows mini-batching.\n",
      "        learning_rate\n",
      "            Step size to use in each optimization step.\n",
      "        loss_function\n",
      "            Loss function to use for training. If `'weighted MSE'`, a weighted\n",
      "            mean squared error is used as loss function, where the weights are\n",
      "            given as the singular values of the corresponding reduced basis\n",
      "            functions. If `None`, the usual mean squared error is used.\n",
      "        restarts\n",
      "            Number of restarts of the training algorithm. Since the training\n",
      "            results highly depend on the initial starting point, i.e. the\n",
      "            initial weights and biases, it is advisable to train multiple\n",
      "            neural networks by starting with different initial values and\n",
      "            choose that one performing best on the validation set.\n",
      "        lr_scheduler\n",
      "            Algorithm to use as learning rate scheduler during training.\n",
      "            If `None`, no learning rate scheduler is used.\n",
      "        lr_scheduler_params\n",
      "            A dictionary of additional parameters passed to the init method of\n",
      "            the learning rate scheduler. The possible parameters depend on the\n",
      "            chosen learning rate scheduler.\n",
      "        es_scheduler_params\n",
      "            A dictionary of additional parameters passed to the init method of\n",
      "            the early stopping scheduler. For the possible parameters,\n",
      "            see :class:`EarlyStoppingScheduler`.\n",
      "        weight_decay\n",
      "            Weighting parameter for the l2-regularization of the weights and\n",
      "            biases in the neural network. This regularization is not available\n",
      "            for all optimizers; see the PyTorch documentation for more details.\n",
      "        log_loss_frequency\n",
      "            Frequency of epochs in which to log the current validation and\n",
      "            training loss during training of the neural networks.\n",
      "            If `0`, no intermediate logging of losses is done.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        rom\n",
      "            Reduced-order |NeuralNetworkModel|.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(nn_reductor.reduce.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47f05b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:01 \u001b[1mNeuralNetworkReductor\u001b[0m: Computing training snapshots ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.1]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.1090909090909091]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.1181818181818182]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.1272727272727273]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.13636363636363635]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.14545454545454545]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.15454545454545454]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.16363636363636364]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.17272727272727273]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.18181818181818182]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.19090909090909092]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.2]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.2090909090909091]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.2181818181818182]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.22727272727272727]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.23636363636363636]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.24545454545454545]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.2545454545454545]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.26363636363636367]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.2727272727272727]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.28181818181818186]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.2909090909090909]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.3]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.3090909090909091]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.3181818181818182]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.32727272727272727]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.33636363636363636]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.34545454545454546]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.3545454545454545]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.36363636363636365]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.3727272727272727]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.38181818181818183]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.3909090909090909]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.4]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.40909090909090906]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.4181818181818182]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.42727272727272725]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.4363636363636364]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.44545454545454544]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.4545454545454546]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.4636363636363636]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.47272727272727266]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.4818181818181818]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.49090909090909085]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.509090909090909]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5181818181818182]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5272727272727272]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5363636363636364]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5454545454545454]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5545454545454546]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5636363636363636]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5727272727272728]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5818181818181818]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5909090909090909]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.609090909090909]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6181818181818182]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6272727272727272]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6363636363636364]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6454545454545454]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6545454545454545]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6636363636363636]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6727272727272727]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6818181818181818]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6909090909090908]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.709090909090909]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7181818181818181]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7272727272727272]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7363636363636363]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7454545454545454]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7545454545454545]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7636363636363636]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7727272727272727]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7818181818181817]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7909090909090909]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7999999999999999]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8090909090909091]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8181818181818181]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8272727272727273]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8363636363636363]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8454545454545453]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8545454545454545]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8636363636363635]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8727272727272727]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8818181818181817]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8909090909090909]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8999999999999999]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9090909090909091]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9181818181818181]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9272727272727272]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9363636363636363]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9454545454545454]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9545454545454545]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9636363636363636]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9727272727272727]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9818181818181817]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9909090909090909]} ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [1.0]} ...\n",
      "00:01 \u001b[1mNeuralNetworkReductor\u001b[0m: Building reduced basis ...\n",
      "00:01 |   \u001b[1mpod\u001b[0m: Computing SVD ...\n",
      "00:01 |   |   \u001b[1mmethod_of_snapshots\u001b[0m: Computing Gramian (100 vectors) ...\n",
      "00:01 |   |   \u001b[1mmethod_of_snapshots\u001b[0m: Computing eigenvalue decomposition ...\n",
      "00:01 |   |   \u001b[1mmethod_of_snapshots\u001b[0m: Computing left-singular vectors (9 vectors) ...\n",
      "00:01 |   \u001b[1mpod\u001b[0m: Checking orthonormality ...\n",
      "00:01 |   \u001b[1mpod\u001b[0m: Reorthogonalizing POD modes ...\n",
      "00:01 \u001b[1mNeuralNetworkReductor\u001b[0m: Computing training samples ...\n",
      "00:01 \u001b[1mNeuralNetworkReductor\u001b[0m: Computing validation snapshots ...\n",
      "00:01 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.796560443700367]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.4949905957768471]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8727381279202442]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7276312261534275]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.18475961309888458]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9780601164730803]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7850257317913176]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8074578747492585]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.2153022694079913]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5053473441060105]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.4337182218093232]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9340884899637416]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6794786080725981]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.840485451943747]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.499072778944598]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.3045148496062992]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5991263083142513]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.1574355304937578]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8448680547933238]} ...\n",
      "00:02 |   \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.6684979592098583]} ...\n",
      "00:02 \u001b[1mNeuralNetworkReductor\u001b[0m: Training of neural network ...\n",
      "00:02 |   \u001b[1mNeuralNetworkReductor\u001b[0m: Initializing neural network ...\n",
      "00:02 |   \u001b[1mFullyConnectedNN\u001b[0m: Architecture of the neural network:\n",
      "FullyConnectedNN(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=30, bias=True)\n",
      "    (1): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (2): Linear(in_features=30, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "00:02 |   \u001b[1mmultiple_restarts_training\u001b[0m: Performing up to 10 restarts to train a neural network with a loss below 1.000e-05 ...\n",
      "00:02 |   \u001b[1mmultiple_restarts_training\u001b[0m: Training neural network #0 ...\n",
      "00:02 |   |   \u001b[1mtrain_neural_network\u001b[0m: Starting optimization procedure ...\n",
      "00:09 |   |   \u001b[1mtrain_neural_network\u001b[0m: Stopping training process early after 341 epochs with validation loss of 5.344e-06 ...\n",
      "00:09 |   \u001b[1mmultiple_restarts_training\u001b[0m: Finished training after 0 restarts, found neural network with loss of 7.755e-06 ...\n",
      "00:09 \u001b[1mNeuralNetworkReductor\u001b[0m: Checking tolerances for error of neural network ...\n",
      "00:09 \u001b[1mNeuralNetworkReductor\u001b[0m: Building ROM ...\n"
     ]
    }
   ],
   "source": [
    "nn_rom = nn_reductor.reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac81fdb-7558-4ddf-87ce-04f61edd29a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced basis size: 9\n",
      "Neural network losses: {'full': 7.75532936792775e-06, 'train': 8.237686756278563e-06, 'val': 5.3435424261736885e-06}\n"
     ]
    }
   ],
   "source": [
    "print(f'Reduced basis size: {len(nn_reductor.reduced_basis)}')\n",
    "print(f'Neural network losses: {nn_reductor.losses}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f12416-dad0-4613-b6b5-cebb8b17e1c1",
   "metadata": {},
   "source": [
    "### Test of the ROM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c5540b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:09 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7822789660768364]} ...\n",
      "00:09 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.7822789660768364]} ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4066323b384ffda0278617d8b2baba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu = parameter_space.sample_randomly()\n",
    "\n",
    "U = fom.solve(mu)\n",
    "U_red = nn_rom.solve(mu)\n",
    "U_red_recon = nn_reductor.reconstruct(U_red)\n",
    "\n",
    "fom.visualize((U, U_red_recon, U-U_red_recon),\n",
    "              legend=(f'Full solution for parameter {mu}', f'Reduced solution for parameter {mu}', f'Difference between solution and approximation'),\n",
    "              separate_colorbars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e95312-258f-458a-8480-b48c4a4fe2f0",
   "metadata": {},
   "source": [
    "### Error and runtime comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da0f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = parameter_space.sample_randomly(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7952b752-76b3-4029-9eae-7b8bfbf087c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def compute_average_errors_and_speedups(rom, reductor):\n",
    "    U = fom.solution_space.empty(reserve=len(test_set))\n",
    "    U_red = fom.solution_space.empty(reserve=len(test_set))\n",
    "\n",
    "    speedups = []\n",
    "    \n",
    "    for mu in test_set:\n",
    "        tic = time.perf_counter()\n",
    "        U.append(fom.solve(mu))\n",
    "        time_fom = time.perf_counter() - tic\n",
    "\n",
    "        tic = time.perf_counter()\n",
    "        U_red.append(reductor.reconstruct(rom.solve(mu)))\n",
    "        time_red = time.perf_counter() - tic\n",
    "\n",
    "        speedups.append(time_fom / time_red)\n",
    "        \n",
    "    absolute_errors = (U - U_red).norm()\n",
    "    relative_errors = (U - U_red).norm() / U.norm()\n",
    "    \n",
    "    return np.average(absolute_errors), np.average(relative_errors), np.average(speedups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "418507fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.4190733713168815]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.4190733713168815]} ...\n",
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.973628221955413]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.973628221955413]} ...\n",
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.9038090091899779]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.9038090091899779]} ...\n",
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.8005451473663857]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.8005451473663857]} ...\n",
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.2751748370667708]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.2751748370667708]} ...\n",
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.5200489033543307]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.5200489033543307]} ...\n",
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.13942338920850592]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.13942338920850592]} ...\n",
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.23886054286079306]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.23886054286079306]} ...\n",
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7147440579182092]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.7147440579182092]} ...\n",
      "00:10 \u001b[1mStationaryModel\u001b[0m: Solving 2DProblem_CG for {input: , mu: [0.7702859403170355]} ...\n",
      "00:10 \u001b[1mNeuralNetworkModel\u001b[0m: Solving 2DProblem_CG_reduced for {input: , mu: [0.7702859403170355]} ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute error: 0.0068720104508320735\n",
      "Average relative error: 8.960207935201087e-05\n",
      "Average speedup: 8.249468919281586\n"
     ]
    }
   ],
   "source": [
    "avg_abs_err, avg_rel_err, avg_speedup = compute_average_errors_and_speedups(nn_rom, nn_reductor)\n",
    "\n",
    "print(f'Average absolute error: {avg_abs_err}')\n",
    "print(f'Average relative error: {avg_rel_err}')\n",
    "print(f'Average speedup: {avg_speedup}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d5aa1ee-1381-47bc-b487-002f0d6a4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_log_levels({'pymor.models.basic.StationaryModel': 'ERROR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe63d5-674a-4083-a008-6a3fbc4a6414",
   "metadata": {},
   "source": [
    "### Exercise (Revision of the `StationaryRBReductor` from the morning session):\n",
    "\n",
    "Set up a `StationaryRBReductor` for the FOM using the same reduced basis as built by the `NeuralNetworkReductor` (the reduced basis can be accessed via `nn_reductor.reduced_basis`) and compute a corresponding ROM. Compute the errors and speedups for the test set from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044aeba-21cb-4801-9559-f671666e046d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7154b14-3dd8-413e-9193-ef9c18e8dfc5",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Create two lists of tuples of parameters and corresponding solutions of the FOM - one for the training set and one for the validation set. Create a new `NeuralNetworkReductor` with these lists as inputs instead of a FOM (use `l2_err=1e-5` and `ann_mse=1e-5` as above). Call the `reduce`-method of the reductor (it might be necessary to increase the number of restarts to train a neural network that reaches the prescribed tolerance) and evaluate the performance of the ROM compared to the FOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b506391-ca52-458e-b5a3-49ae8c1e4677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb603c8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extending the problem by output quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8c2b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = problem.with_(outputs=[('l2', problem.rhs), ('l2_boundary', problem.dirichlet_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f8620fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fom, _ = discretize_stationary_cg(problem, diameter=1/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d7aa553",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:10 \u001b[1mNeuralNetworkStatefreeOutputReductor\u001b[0m: Computing training samples ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputReductor\u001b[0m: Computing validation snapshots ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputReductor\u001b[0m: Training of neural network ...\n",
      "00:11 |   \u001b[1mNeuralNetworkStatefreeOutputReductor\u001b[0m: Initializing neural network ...\n",
      "00:11 |   \u001b[1mFullyConnectedNN\u001b[0m: Architecture of the neural network:\n",
      "FullyConnectedNN(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=9, bias=True)\n",
      "    (1): Linear(in_features=9, out_features=9, bias=True)\n",
      "    (2): Linear(in_features=9, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "00:11 |   \u001b[1mmultiple_restarts_training\u001b[0m: Performing up to 10 restarts to train a neural network with a loss below 1.000e-05 ...\n",
      "00:11 |   \u001b[1mmultiple_restarts_training\u001b[0m: Training neural network #0 ...\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Starting optimization procedure ...\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 0: Current train loss of 1.299e-02\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 0: Current val loss of 1.103e-02\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 2: Current train loss of 2.717e-04\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 2: Current val loss of 2.839e-04\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 4: Current train loss of 4.436e-05\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 4: Current val loss of 3.961e-05\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 6: Current train loss of 9.059e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 6: Current val loss of 7.163e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 8: Current train loss of 5.897e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 8: Current val loss of 3.221e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 10: Current train loss of 5.879e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 10: Current val loss of 3.318e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 12: Current train loss of 5.879e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 12: Current val loss of 3.318e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 14: Current train loss of 5.879e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 14: Current val loss of 3.318e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 16: Current train loss of 5.879e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 16: Current val loss of 3.318e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 18: Current train loss of 5.879e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Epoch 18: Current val loss of 3.318e-06\n",
      "00:11 |   |   \u001b[1mtrain_neural_network\u001b[0m: Stopping training process early after 19 epochs with validation loss of 3.221e-06 ...\n",
      "00:11 |   \u001b[1mmultiple_restarts_training\u001b[0m: Finished training after 0 restarts, found neural network with loss of 5.451e-06 ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputReductor\u001b[0m: Using neural network with smallest validation error ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputReductor\u001b[0m: Finished training with a validation loss of 3.220633641367358e-06 ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputReductor\u001b[0m: Building ROM ...\n"
     ]
    }
   ],
   "source": [
    "from pymor.reductors.neural_network import NeuralNetworkStatefreeOutputReductor\n",
    "\n",
    "output_reductor = NeuralNetworkStatefreeOutputReductor(fom,\n",
    "                                                       training_set,\n",
    "                                                       validation_set,\n",
    "                                                       validation_loss=1e-5)\n",
    "\n",
    "output_rom = output_reductor.reduce(log_loss_frequency=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f129c440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.4190733713168815]} ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.973628221955413]} ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.9038090091899779]} ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.8005451473663857]} ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.2751748370667708]} ...\n",
      "00:11 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.5200489033543307]} ...\n",
      "00:12 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.13942338920850592]} ...\n",
      "00:12 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.23886054286079306]} ...\n",
      "00:12 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.7147440579182092]} ...\n",
      "00:12 \u001b[1mNeuralNetworkStatefreeOutputModel\u001b[0m: Solving 2DProblem_CG_output_reduced for {input: , mu: [0.7702859403170355]} ...\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "outputs_red = []\n",
    "outputs_speedups = []\n",
    "\n",
    "for mu in test_set:\n",
    "    tic = time.perf_counter()\n",
    "    outputs.append(fom.output(mu=mu))\n",
    "    time_fom = time.perf_counter() - tic\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    outputs_red.append(output_rom.output(mu=mu))\n",
    "    time_red = time.perf_counter() - tic\n",
    "    \n",
    "    outputs_speedups.append(time_fom / time_red)\n",
    "\n",
    "outputs = np.squeeze(np.array(outputs))\n",
    "outputs_red = np.squeeze(np.array(outputs_red))\n",
    "\n",
    "outputs_absolute_errors = np.abs(outputs - outputs_red)\n",
    "outputs_relative_errors = np.abs(outputs - outputs_red) / np.abs(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1024de9-3098-4725-a299-3b7b2b0bbe63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute error: 0.0013971907838333686\n",
      "Average relative error: 0.0004165336350060543\n",
      "Average speedup: 11.294453029588952\n"
     ]
    }
   ],
   "source": [
    "print(f'Average absolute error: {np.average(outputs_absolute_errors)}')\n",
    "print(f'Average relative error: {np.average(outputs_relative_errors)}')\n",
    "print(f'Average speedup: {np.average(outputs_speedups)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4a5eb-f3a0-41b2-bd10-505479d0a56a",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Set up a new `NeuralNetworkReductor` for the changed FOM (which now includes the output quantities) with the same tolerances. Use this new reductor to compute a ROM that also takes the output into account and compare the results on the test set with those from the `NeuralNetworkStatefreeOutputReductor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999d78a-1cda-4acf-a7b4-2f90bf14cbda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3610593c-35a8-4aaa-85e3-92f9159fd176",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- pyMOR provides highly customizable training routines for neural networks with various options and parameters to tune\n",
    "- Implementation respects abstract interfaces, i.e. the reductors can be directly applied to models/solutions originating from external solvers (see for instance https://github.com/pymor/pymor/blob/main/src/pymordemos/neural_networks_instationary.py for an example of Navier-Stokes equations using the FEniCS bindings in pyMOR)\n",
    "- Applicable to stationary and instationary problems\n",
    "- Different architecture called long short-term memory (LSTM) neural networks is also available for instationary problems (this architecture is closely related to time-stepping schemes)"
   ]
  }
 ],
 "metadata": {
  "jupyter": {
   "jupytext": {
    "cell_metadata_filter": "-all",
    "formats": "ipynb,myst",
    "main_language": "python",
    "text_representation": {
     "extension": ".md",
     "format_name": "myst",
     "format_version": "1.3",
     "jupytext_version": "1.11.2"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
